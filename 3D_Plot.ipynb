{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hRFl2s4Ccm4G"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pathlib\n",
    "import pydicom\n",
    "import os\n",
    "from pydicom.pixel_data_handlers.util import apply_modality_lut\n",
    "from scipy import ndimage\n",
    "from skimage import morphology\n",
    "import plotly.graph_objects as go\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# Display\n",
    "from IPython.display import Image, display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tRv8602fcm4M",
    "outputId": "ace77306-b498-4135-b55f-64dcc726e237"
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = (224, 224)\n",
    "NUM_EPOCHS = 2\n",
    "SPLIT = 0.15\n",
    "DATASET_PATH = r'C:\\Users\\adais\\Documents\\CovidX CT\\divided data'\n",
    "#TRAIN_PATH = r'D:\\Python\\Covid NN\\ct-scan-transfer-learning\\DIVIDED DATASET\\train'\n",
    "#VAL_PATH = r'D:\\Python\\Covid NN\\ct-scan-transfer-learning\\DIVIDED DATASET\\val'\n",
    "\n",
    "class MyThresholdCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, threshold):\n",
    "        super(MyThresholdCallback, self).__init__()\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_acc = logs[\"val_accuracy\"]\n",
    "        train_acc = logs[\"accuracy\"]\n",
    "        if val_acc >= self.threshold and train_acc >= self.threshold:\n",
    "            self.model.stop_training = True\n",
    "\n",
    "acc_callback = MyThresholdCallback(0.99)\n",
    "\n",
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(directory=DATASET_PATH,\n",
    "                                                                    shuffle=True,\n",
    "                                                                    validation_split=SPLIT,\n",
    "                                                                    image_size=IMG_SIZE,\n",
    "                                                                    color_mode=\"rgb\", label_mode=\"categorical\",\n",
    "                                                                    labels=\"inferred\", seed=15,\n",
    "                                                                    subset=\"training\", batch_size=32)\n",
    "\n",
    "val_dataset = tf.keras.preprocessing.image_dataset_from_directory(directory=DATASET_PATH,\n",
    "                                                                    shuffle=True,\n",
    "                                                                    validation_split=SPLIT,\n",
    "                                                                    image_size=IMG_SIZE,\n",
    "                                                                    color_mode=\"rgb\", label_mode=\"categorical\",\n",
    "                                                                    labels=\"inferred\", seed=15,\n",
    "                                                                    subset=\"validation\", batch_size=32)\n",
    "base_model = tf.keras.applications.VGG19(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "base_model.trainable = False\n",
    "\n",
    "outputs = base_model.output\n",
    "outputs= layers.AveragePooling2D((2,2),strides=(2,2))(outputs)\n",
    "outputs = layers.Flatten(name=\"flatten\")(outputs)\n",
    "outputs = layers.Dense(1024, activation=\"relu\")(outputs)\n",
    "outputs = layers.Dropout(0.2)(outputs)\n",
    "outputs = layers.Dense(512, activation=\"relu\")(outputs)\n",
    "outputs = layers.Dropout(0.2)(outputs)\n",
    "outputs = layers.Dense(64, activation=\"relu\")(outputs)\n",
    "outputs = layers.Dense(2, activation=\"softmax\")(outputs)\n",
    "final_model = tf.keras.Model(inputs=base_model.input, outputs=outputs)\n",
    "\n",
    "final_model.compile(optimizer='adam',\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "final_model.summary()\n",
    "history = final_model.fit(train_dataset.take(50),\n",
    "                           validation_data=val_dataset.take(50),\n",
    "                           epochs=NUM_EPOCHS, callbacks=[acc_callback], batch_size=32)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=[x for x in range(NUM_EPOCHS)],\n",
    "                         y=history.history['accuracy'],\n",
    "                         mode='lines',\n",
    "                         name='Training',\n",
    "                         ))\n",
    "fig.add_trace(go.Scatter(x=[x for x in range(NUM_EPOCHS)],\n",
    "                         y=history.history['val_accuracy'],\n",
    "                         mode='lines',\n",
    "                         name='Validation'))\n",
    "\n",
    "fig.update_layout(title='VGG19', xaxis_title='Epoch', yaxis_title='Accuracy')\n",
    "#fig.write_html(\"history_plot_VGG19_final_Sao Paulo.html\")\n",
    "history_dict = history.history\n",
    "#json.dump(history_dict, open('VGG19_training_log_Sao Paulo', 'w'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O8HilLO7cm4O"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as K\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.preprocessing import image\n",
    "\n",
    "def VizGradCAM(model, image, interpolant=0.5, plot_results=True):\n",
    "    assert (\n",
    "        interpolant > 0 and interpolant < 1\n",
    "    ), \"Heatmap Interpolation Must Be Between 0 - 1\"\n",
    "\n",
    "    last_conv_layer = next(\n",
    "        x for x in model.layers[::-1] if isinstance(x, K.layers.Conv2D)\n",
    "    )\n",
    "    target_layer = model.get_layer(last_conv_layer.name)\n",
    "    original_img = image\n",
    "    img = np.expand_dims(original_img, axis=0)\n",
    "    prediction = model.predict(img)\n",
    "\n",
    "    # Obtain Prediction Index\n",
    "    prediction_idx = np.argmax(prediction)\n",
    "\n",
    "    # Compute Gradient of Top Predicted Class\n",
    "    with tf.GradientTape() as tape:\n",
    "        gradient_model = Model([model.inputs], [target_layer.output, model.output])\n",
    "        conv2d_out, prediction = gradient_model(img)\n",
    "        # Obtain the Prediction Loss\n",
    "        loss = prediction[:, prediction_idx]\n",
    "\n",
    "    gradients = tape.gradient(loss, conv2d_out)\n",
    "    output = conv2d_out[0]\n",
    "    weights = tf.reduce_mean(gradients[0], axis=(0, 1))\n",
    "    activation_map = np.zeros(output.shape[0:2], dtype=np.float32)\n",
    "\n",
    "    for idx, weight in enumerate(weights):\n",
    "        activation_map += weight * output[:, :, idx]\n",
    "\n",
    "    # Resize\n",
    "    activation_map = cv2.resize(\n",
    "        activation_map.numpy(), (original_img.shape[1], original_img.shape[0])\n",
    "    )\n",
    "    activation_map = np.maximum(activation_map, 0)\n",
    "\n",
    "    # Convert to 0/255\n",
    "    activation_map = (activation_map - activation_map.min()) / (\n",
    "        activation_map.max() - activation_map.min()\n",
    "    )\n",
    "    activation_map = np.uint8(255 * activation_map)\n",
    "\n",
    "    # Convert to Heatmap\n",
    "    heatmap = cv2.applyColorMap(activation_map, cv2.COLORMAP_JET)\n",
    "\n",
    "    # Superimpose Heatmap on Image Data\n",
    "    original_img = np.uint8(\n",
    "        (original_img - original_img.min())\n",
    "        / (original_img.max() - original_img.min())\n",
    "        * 255\n",
    "    )\n",
    "    cvt_heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
    "    plt.rcParams[\"figure.dpi\"] = 100\n",
    "    return cvt_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "63vgZ6tNcm4P"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from skimage import transform\n",
    "def load(np_image):\n",
    "   np_image = np.array(np_image).astype('float32')/255\n",
    "   np_image = transform.resize(np_image, (224, 224, 3))\n",
    "   #np_image = np.expand_dims(np_image, axis=0)\n",
    "   return np_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uMp5w_fkcm4Q"
   },
   "outputs": [],
   "source": [
    "DATASET_ABSOLUTE_PATH = r\"C:\\Users\\adais\\Documents\\COVID DICOM\\manifest-1608266677008\\MIDRC-RICORD-1A\\MIDRC-RICORD-1A-419639-000421\\12-05-2006-NA-CT CHEST WITHOUT CONTRAST-50477\"\n",
    "\n",
    "# Will load images from directories, convert them to pixel arrays with HU values\n",
    "# and return array of arrays (distinct images)\n",
    "\n",
    "heat_maps = []\n",
    "\n",
    "def load_dicom_dataset(directory):\n",
    "    dataset_to_return = []\n",
    "    dataset_path = pathlib.Path(directory)\n",
    "    for data_sample in dataset_path.iterdir():\n",
    "        single_sample_list = []\n",
    "        if os.path.isfile(pathlib.Path(data_sample)):\n",
    "            continue\n",
    "        img_index = 0\n",
    "        for image in data_sample.iterdir():\n",
    "            source_image_file = pydicom.dcmread(pathlib.Path(image), force=True)\n",
    "            image_array = source_image_file.pixel_array      \n",
    "            #image_array = image_array[::2, ::2]\n",
    "            # PREDICTION\n",
    "            if 110 > img_index > 100:\n",
    "                heat_maps.append(VizGradCAM(final_model, load(image_array)))\n",
    "            \n",
    "            hu_image_array = apply_modality_lut(image_array, source_image_file)\n",
    "            masked_image = remove_data_noise(hu_image_array)\n",
    "            \n",
    "            single_sample_list.append(list(masked_image))\n",
    "            img_index += 1\n",
    "        dataset_to_return.append(single_sample_list)\n",
    "    return dataset_to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aKY6v6u8cm4Q"
   },
   "outputs": [],
   "source": [
    "def remove_data_noise(hu_image): # Masking the image\n",
    "    hu_image = crop_image(hu_image, 350, 340)\n",
    "\n",
    "    segmentation = morphology.dilation(hu_image, np.ones((1, 1)))\n",
    "    labels, label_nb = ndimage.label(segmentation)\n",
    "    label_count = np.bincount(labels.ravel().astype(np.int))\n",
    "    label_count[0] = 0\n",
    "\n",
    "    mask = labels == label_count.argmax()\n",
    "\n",
    "    mask = morphology.dilation(mask, np.ones((1, 1)))\n",
    "    mask = ndimage.morphology.binary_fill_holes(mask)\n",
    "    mask = morphology.dilation(mask, np.ones((3, 3)))\n",
    "\n",
    "    masked_image = mask * hu_image\n",
    "    return masked_image\n",
    "\n",
    "def crop_image(image, cropx, cropy): # Cropping image equally from both sides\n",
    "    y,x = image.shape\n",
    "    startx = x // 2 - (cropx // 2)\n",
    "    starty = y // 2 - (cropy // 2)\n",
    "    return image[starty:starty + cropy, startx:startx + cropx]\n",
    "\n",
    "def plot_3d_image(heat_map_array): # #3D plotting\n",
    "#     z, x, y = data_array.nonzero()\n",
    "#     marker_data = go.Scatter3d(\n",
    "#         x=x, y=y, z=z,\n",
    "#         marker=go.scatter3d.Marker(size=1),\n",
    "#         opacity=0.15,\n",
    "#         mode='markers', marker_color='rgba(39, 39, 245, 0.8)'\n",
    "#     )\n",
    "    z, x, y = heat_map_array.nonzero()\n",
    "    heat_marker_data = go.Scatter3d(\n",
    "        x=x, y=y, z=z,\n",
    "        marker=go.scatter3d.Marker(size=1),\n",
    "        opacity=0.15,\n",
    "        mode='markers', marker_color='rgba(245, 39, 56, 0.8)'\n",
    "    )\n",
    "    fig = go.Figure(data=heat_marker_data)\n",
    "    fig.update_layout(width=700, margin=dict(r=10, l=10, b=10, t=10))\n",
    "    fig.update_layout(scene_aspectmode='cube')\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L6-Do5ORcm4S",
    "outputId": "c48f8e88-5eff-4ee3-aa35-00c57cde035d"
   },
   "outputs": [],
   "source": [
    "heat_maps = []\n",
    "\n",
    "dataset = load_dicom_dataset(DATASET_ABSOLUTE_PATH)\n",
    "\n",
    "average_shape_array = np.mean(np.array([patient for patient in dataset]), axis=0)\n",
    "upper_hu_bound = average_shape_array < -620\n",
    "lower_hu_bound = average_shape_array > -740\n",
    "average_shape_array = np.where((lower_hu_bound == upper_hu_bound), upper_hu_bound, 0)\n",
    "\n",
    "\n",
    "heat_maps_gray = [np.mean(x, axis=2) for x in heat_maps]\n",
    "heat_maps_gray = [cv2.resize(x, dsize=(340, 350), interpolation=cv2.INTER_CUBIC) for x in heat_maps_gray]\n",
    "heat_maps_gray = np.array(heat_maps_gray)\n",
    "print(average_shape_array)\n",
    "\n",
    "#plot_3d_image(heat_maps_gray)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "3D Plot.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
