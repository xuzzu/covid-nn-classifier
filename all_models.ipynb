{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_zyHnbpiU1g"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import plotly.graph_objects as go\n",
        "import json\n",
        "from tensorflow.keras import layers\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import tensorflow.keras as K\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.transform import resize\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from keras.preprocessing import image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGyjoT7iiU1h"
      },
      "outputs": [],
      "source": [
        "class MyThresholdCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, threshold):\n",
        "        super(MyThresholdCallback, self).__init__()\n",
        "        self.threshold = threshold\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        val_acc = logs[\"val_accuracy\"]\n",
        "        train_acc = logs[\"accuracy\"]\n",
        "        if val_acc >= self.threshold and train_acc >= self.threshold:\n",
        "            self.model.stop_training = True\n",
        "\n",
        "def plot_training(history_dict, model_name, dataset_name):\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatter(x=[x for x in range(NUM_EPOCHS)],\n",
        "                             y=history_dict.history['accuracy'],\n",
        "                             mode='lines',\n",
        "                             name='Training',\n",
        "                             ))\n",
        "#     fig.add_trace(go.Scatter(x=[x for x in range(NUM_EPOCHS)],\n",
        "#                              y=history_dict.history['val_accuracy'],\n",
        "#                              mode='lines',\n",
        "#                              name='Validation'))\n",
        "    fig.update_layout(title=model_name, xaxis_title='Epoch', yaxis_title='Accuracy')\n",
        "    fig.write_html(f\"history_plot_{model_name}_{dataset_name}.html\")\n",
        "\n",
        "def densenet201():\n",
        "    base_model = tf.keras.applications.DenseNet201(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
        "    base_model.trainable = False\n",
        "\n",
        "    outputs = base_model.output\n",
        "    outputs = tf.keras.layers.GlobalAveragePooling2D()(outputs)\n",
        "    outputs = tf.keras.layers.BatchNormalization()(outputs)\n",
        "    outputs = tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.L1L2(l1=1e-4, l2=1e-4))(outputs)\n",
        "    outputs = tf.keras.layers.Dropout(0.5)(outputs)\n",
        "    outputs = tf.keras.layers.BatchNormalization()(outputs)\n",
        "    outputs = tf.keras.layers.Dense(128, activation='relu', kernel_initializer='he_uniform')(outputs)\n",
        "    outputs = tf.keras.layers.Dropout(0.3)(outputs)\n",
        "    predicts = layers.Dense(2, activation=\"softmax\")(outputs)\n",
        "\n",
        "    final_model = tf.keras.Model(inputs=base_model.input, outputs=predicts, name='densenet201')\n",
        "    return final_model\n",
        "\n",
        "def vgg16():\n",
        "    base_model = tf.keras.applications.VGG16(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
        "    base_model.trainable = False\n",
        "\n",
        "    outputs = base_model.output\n",
        "    outputs = layers.AveragePooling2D((2, 2), strides=(2, 2))(outputs)\n",
        "    outputs = layers.Flatten(name=\"flatten\")(outputs)\n",
        "    outputs = layers.Dense(1024, activation=\"relu\")(outputs)\n",
        "    outputs = layers.Dropout(0.2)(outputs)\n",
        "    outputs = layers.Dense(512, activation=\"relu\")(outputs)\n",
        "    outputs = layers.Dropout(0.2)(outputs)\n",
        "    outputs = layers.Dense(64, activation=\"relu\")(outputs)\n",
        "    predicts = layers.Dense(2, activation=\"softmax\")(outputs)\n",
        "\n",
        "    final_model = tf.keras.Model(inputs=base_model.input, outputs=predicts, name='vgg16')\n",
        "    return final_model\n",
        "\n",
        "def vgg19():\n",
        "    base_model = tf.keras.applications.VGG19(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
        "    base_model.trainable = False\n",
        "\n",
        "    outputs = base_model.output\n",
        "    outputs = layers.AveragePooling2D((2, 2), strides=(2, 2))(outputs)\n",
        "    outputs = layers.Flatten(name=\"flatten\")(outputs)\n",
        "    outputs = layers.Dense(1024, activation=\"relu\")(outputs)\n",
        "    outputs = layers.Dropout(0.2)(outputs)\n",
        "    outputs = layers.Dense(512, activation=\"relu\")(outputs)\n",
        "    outputs = layers.Dropout(0.2)(outputs)\n",
        "    outputs = layers.Dense(64, activation=\"relu\")(outputs)\n",
        "    predicts = layers.Dense(2, activation=\"softmax\")(outputs)\n",
        "\n",
        "    final_model = tf.keras.Model(inputs=base_model.input, outputs=predicts, name='vgg19')\n",
        "    return final_model\n",
        "\n",
        "def xception():\n",
        "    base_model = tf.keras.applications.Xception(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
        "    base_model.trainable = False\n",
        "\n",
        "    outputs = base_model.output\n",
        "    outputs = layers.experimental.preprocessing.RandomRotation((-0.15, 0.15))(outputs)\n",
        "    outputs = layers.experimental.preprocessing.RandomFlip('horizontal')(outputs)\n",
        "    outputs = layers.GlobalMaxPooling2D()(outputs)\n",
        "    outputs = tf.keras.layers.BatchNormalization()(outputs)\n",
        "    outputs = tf.keras.layers.Dense(units=512, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=tf.keras.regularizers.L1L2())(outputs)\n",
        "    outputs = tf.keras.layers.GaussianDropout(0.5)(outputs)\n",
        "    outputs = tf.keras.layers.Dense(units=128, activation='relu')(outputs)\n",
        "    outputs = tf.keras.layers.GaussianDropout(0.5)(outputs)\n",
        "    outputs = tf.keras.layers.BatchNormalization()(outputs)\n",
        "    predicts = layers.Dense(2, activation=\"softmax\")(outputs)\n",
        "\n",
        "    final_model = tf.keras.Model(inputs=base_model.input, outputs=predicts, name='xception')\n",
        "    return final_model\n",
        "\n",
        "def inceptionv3():\n",
        "    base_model = tf.keras.applications.InceptionV3(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
        "    base_model.trainable = False\n",
        "\n",
        "    outputs = base_model.output\n",
        "    outputs = tf.keras.layers.GlobalAveragePooling2D()(outputs)\n",
        "    outputs = tf.keras.layers.BatchNormalization()(outputs)\n",
        "    outputs = tf.keras.layers.Dense(312, activation='relu', kernel_regularizer=tf.keras.regularizers.L1L2(l1=2e-5, l2=1e-4))(outputs)\n",
        "    outputs = tf.keras.layers.Dropout(0.5)(outputs)\n",
        "    outputs = tf.keras.layers.BatchNormalization()(outputs)\n",
        "    outputs = tf.keras.layers.Dense(128, activation='relu', kernel_initializer='he_uniform')(outputs)\n",
        "    outputs = tf.keras.layers.Dropout(0.3)(outputs)\n",
        "    predicts = layers.Dense(2, activation=\"softmax\")(outputs)\n",
        "\n",
        "    final_model = tf.keras.Model(inputs=base_model.input, outputs=predicts, name='inceptionv3')\n",
        "    return final_model\n",
        "\n",
        "def mobilenetv2():\n",
        "    base_model = tf.keras.applications.MobileNetV2(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
        "    base_model.trainable = False\n",
        "\n",
        "    outputs = base_model.output\n",
        "    outputs = layers.AveragePooling2D((2, 2), strides=(2, 2))(outputs)\n",
        "    outputs = layers.Flatten(name=\"flatten\")(outputs)\n",
        "    outputs = layers.Dense(1024, activation=\"relu\")(outputs)\n",
        "    outputs = layers.Dropout(0.2)(outputs)\n",
        "    outputs = layers.Dense(512, activation=\"relu\")(outputs)\n",
        "    outputs = layers.Dropout(0.2)(outputs)\n",
        "    outputs = layers.Dense(64, activation=\"relu\")(outputs)\n",
        "    predicts = layers.Dense(2, activation=\"softmax\")(outputs)\n",
        "\n",
        "    final_model = tf.keras.Model(inputs=base_model.input, outputs=predicts, name='mobilenetv2')\n",
        "    return final_model\n",
        "\n",
        "def resnet50v2():\n",
        "    base_model = tf.keras.applications.ResNet50V2(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
        "    base_model.trainable = False\n",
        "\n",
        "    outputs = base_model.output\n",
        "    outputs = tf.keras.layers.GlobalAveragePooling2D()(outputs)\n",
        "    outputs = tf.keras.layers.BatchNormalization()(outputs)\n",
        "    outputs = tf.keras.layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.L1L2(l1=1e-4, l2=1e-4))(outputs)\n",
        "    outputs = tf.keras.layers.Dropout(0.5)(outputs)\n",
        "    outputs = tf.keras.layers.BatchNormalization()(outputs)\n",
        "    outputs = tf.keras.layers.Dense(128, activation='relu', kernel_initializer='he_uniform')(outputs)\n",
        "    outputs = tf.keras.layers.Dropout(0.3)(outputs)\n",
        "    predicts = layers.Dense(2, activation=\"softmax\")(outputs)\n",
        "\n",
        "    final_model = tf.keras.Model(inputs=base_model.input, outputs=predicts, name='resnet50v2')\n",
        "    return final_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "viQVbQkTiU1l"
      },
      "outputs": [],
      "source": [
        "# Constants and Parameters\n",
        "IMG_SIZE = (224, 224)\n",
        "NUM_EPOCHS = 15\n",
        "SPLIT = 0.15\n",
        "ACCURACY_THRESHOLD = 0.99\n",
        "DATASET_NAME = ''\n",
        "ROOT_DATASETS_PATH = r'C:\\Users\\504\\Documents'\n",
        "TRAIN_DATASET_PATH = fr'{ROOT_DATASETS_PATH}\\{DATASET_NAME}\\train'\n",
        "VAL_DATASET_PATH = fr'{ROOT_DATASETS_PATH}\\{DATASET_NAME}\\val'\n",
        "TEST_DATASET_PATH = fr'{ROOT_DATASETS_PATH}\\{DATASET_NAME}\\test'\n",
        "\n",
        "#acc_callback = MyThresholdCallback(ACCURACY_THRESHOLD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFCaf0woiU1l"
      },
      "outputs": [],
      "source": [
        "# Data pipeline\n",
        "def make_generators(dataset_name):\n",
        "    DATASET_NAME = dataset_name\n",
        "    TRAIN_DATASET_PATH = fr'{ROOT_DATASETS_PATH}\\{DATASET_NAME}\\train'\n",
        "    #VAL_DATASET_PATH = fr'{ROOT_DATASETS_PATH}\\{DATASET_NAME}\\val'\n",
        "    train_dataset = tf.keras.preprocessing.image_dataset_from_directory(directory=TRAIN_DATASET_PATH,\n",
        "                                                                    shuffle=True,\n",
        "                                                                    validation_split=SPLIT,\n",
        "                                                                    image_size=IMG_SIZE,\n",
        "                                                                    color_mode=\"rgb\", label_mode=\"categorical\",\n",
        "                                                                    seed=15,\n",
        "                                                                    subset=\"training\", batch_size=32)\n",
        "\n",
        "    val_dataset = tf.keras.preprocessing.image_dataset_from_directory(directory=TRAIN_DATASET_PATH,\n",
        "                                                                        shuffle=True,\n",
        "                                                                        validation_split=SPLIT,\n",
        "                                                                        image_size=IMG_SIZE,\n",
        "                                                                        color_mode=\"rgb\", label_mode=\"categorical\",\n",
        "                                                                        seed=15,\n",
        "                                                                        subset=\"validation\", batch_size=32)\n",
        "\n",
        "    DATASET_NAME = ''\n",
        "    return (train_dataset, val_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_NqiOmguiU1m"
      },
      "outputs": [],
      "source": [
        "# Compilation and training\n",
        "models_list = [densenet201(), vgg16(), vgg19(), xception(), inceptionv3(), mobilenetv2(), resnet50v2()]\n",
        "datasets_list = ['CovidX', 'SaoPaulo', 'UCSD']\n",
        "# trained_models_list = dict()\n",
        "final_pred = 0.0\n",
        "i = 0\n",
        "for dataset in datasets_list:\n",
        "  \n",
        "    train_datagen, val_datagen = make_generators(dataset)\n",
        "    for model in models_list:\n",
        "        model.compile(optimizer='nadam',\n",
        "                      loss='categorical_crossentropy',\n",
        "                      metrics=['accuracy',\n",
        "                               tf.keras.metrics.Precision(name='prec'),\n",
        "                               tf.keras.metrics.Recall(name='recall'),\n",
        "                               tf.keras.metrics.TruePositives(name='tp'),\n",
        "                               tf.keras.metrics.TrueNegatives(name='tn'),\n",
        "                               tf.keras.metrics.FalsePositives(name='fp'),\n",
        "                               tf.keras.metrics.FalseNegatives(name='fn')])\n",
        "        with tf.device('/device:GPU:0'):\n",
        "            history = model.fit(train_datagen.take(10),\n",
        "                                validation_data=val_datagen.take(10),\n",
        "                                epochs=NUM_EPOCHS,\n",
        "                                batch_size=32)\n",
        "        final_pred += model.predict_proba(val_datagen)\n",
        "        i+=1\n",
        "        print(final_pred)\n",
        "        #plot_training(history, model.name, dataset)\n",
        "        #model.save_weights(fr'/saved_weights/{model.name}' + f'[{dataset}]')\n",
        "        #model.save(fr'/saved_models/{model.name}' + f'[{dataset}]')\n",
        "        print('\\n\\n\\n')\n",
        "        print(model.name + f'[{dataset}]')\n",
        "        print('\\n\\n\\n')\n",
        "        model_enc = model.name + f'[{dataset}]'\n",
        "        trained_models[model_enc] = [model, dataset]\n",
        "final_pred /= i\n",
        "print(final_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xcoYh0miU1m"
      },
      "outputs": [],
      "source": [
        "def make_test_generator(dataset_name):\n",
        "    DATASET_NAME = dataset_name\n",
        "    TEST_DATASET_PATH = fr'{ROOT_DATASETS_PATH}/{DATASET_NAME}/test'\n",
        "    test_dataset = tf.keras.preprocessing.image_dataset_from_directory(directory=TEST_DATASET_PATH,\n",
        "                                                                    shuffle=True,\n",
        "                                                                    image_size=IMG_SIZE,\n",
        "                                                                    color_mode=\"rgb\", label_mode=\"categorical\",\n",
        "                                                                    batch_size=32)\n",
        "    return test_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPcXlWwkiU1m"
      },
      "outputs": [],
      "source": [
        "# Evaluation\n",
        "metrics_dictionary = dict()\n",
        "for model in trained_models:\n",
        "    if trained_models[model][1] not in datasets_list:\n",
        "        continue\n",
        "    test_datagen = make_test_generator(trained_models[model][1])\n",
        "    metrics = trained_models[model][0].evaluate(test_datagen, return_dict=True)\n",
        "    metrics_dictionary[model] = metrics\n",
        "json.dump(metrics_dictionary, open(r'logs_dictionary.json', 'w'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5AM9gHMuiU1l"
      },
      "outputs": [],
      "source": [
        "assert tf.test.is_gpu_available()\n",
        "assert tf.test.is_built_with_cuda()\n",
        "tf.config.list_physical_devices()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "all-models.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}